{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y1ScXcnuTks5"
   },
   "source": [
    "# Intesa Sanpaolo: AI4Citizens\n",
    "\n",
    "## Tutorial Reti Neurali\n",
    "\n",
    "In questo tutorial impareremo a:\n",
    "- usare la **differenziazione automatica**;\n",
    "- costruire e allenare una [rete neurale artificiale](https://www.wikiwand.com/it/Rete_neurale_artificiale) usando Tensorflow; \n",
    "- migliorare le performance di una rete neurale usando alcuni accorgimenti di base;\n",
    "- usare il **Transfer Learning** sfruttando i pesi di una rete allenata su un dataset di un altro dominio; \n",
    "- generare dati sintetici usando gli **autoencoder**;\n",
    "- costruire una **GAN**.\n",
    "\n",
    "Punti di attenzione:\n",
    "- dato il poco tempo a disposizione, questo tutorial vuole essere una piccola introduzione per iniziare a usare Tensorflow velocemente. Per una trattazione esaustiva, si prega di consultare la [documentazione ufficiale](https://www.tensorflow.org/api_docs);\n",
    "- questo notebook contenente tutto il codice presentato sarà sempre a vostra disposizione;    \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7lmeiBk5ySkP"
   },
   "source": [
    "### Installazione pacchetti mancanti e aggiornamento Tensorflow\n",
    "\n",
    "Su Colab è possibile eseguire comandi di terminale anteponendo il punto escamativo \"!\" al comando che vogliamo dare. Nella cella qui sotto andiamo a installare il pacchetto [emnist](https://www.nist.gov/itl/products-and-services/emnist-dataset) usando pip. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u5P5LyFwvHDJ",
    "outputId": "bf0c2fab-5e70-4ad2-c33a-c1aaca6fc0d2"
   },
   "outputs": [],
   "source": [
    "! pip install emnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_-NhleiYyQBq",
    "outputId": "229c8369-0990-4d42-db75-2dcffc4ebede"
   },
   "outputs": [],
   "source": [
    "! pip freeze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c_ZEJF16yYPF"
   },
   "source": [
    "### Caricamento pacchetti\n",
    "\n",
    "Importiamo alcune funzioni/oggetti che useremo dopo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A8xu3Vebtlry"
   },
   "outputs": [],
   "source": [
    "from emnist import extract_training_samples, extract_test_samples\n",
    "from matplotlib.pyplot import matshow, subplots, hist, show\n",
    "from numpy import unique, prod, arange, exp, minimum, argmax\n",
    "from numpy.random import randint, choice, normal\n",
    "from string import ascii_lowercase\n",
    "from tensorflow import GradientTape, constant as tf_constant, Variable, \\\n",
    "ones_like, zeros_like, function as tf_function, __version__ as tf_version\n",
    "from tensorflow.data import Dataset\n",
    "from tensorflow.random import normal as tf_normal\n",
    "from tensorflow.math import reduce_mean as tf_reduce_mean, sqrt as tf_sqrt\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Flatten, Conv2D, \\\n",
    "MaxPool2D, Reshape, BatchNormalization, Activation, LeakyReLU, Conv2DTranspose,\\\n",
    "LeakyReLU, Concatenate, RandomTranslation, RandomRotation\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy, \\\n",
    "MeanSquaredError, BinaryCrossentropy, CategoricalCrossentropy\n",
    "from tensorflow.keras.utils import set_random_seed\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import plot_model, to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.metrics import Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7555U9hRzCQh"
   },
   "source": [
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wAHwU-dVe9qs"
   },
   "source": [
    "### Differenziazione automatica\n",
    "\n",
    "Data una funzione *bella* $y = f(x)$ e un punto del suo dominio $x_0$, voglio sapere in quale direzione mi devo muovere per raggiungere un punto di minimo. Per esempio, $y = x^2$ e $x_0=3$. La derivata è $y'(x) = 2x$ e $y'(3) = 6$. Per raggiungere il minimo (che si trova in $x=0$), dobbiamo andare nella direzione opposta. L'operazione di differenziazione automatica è già implementata in Tensorflow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ow3O5eT7WbNk",
    "outputId": "2c0d7b7f-7b68-4ef7-9bd5-17ec6dfc4db6"
   },
   "outputs": [],
   "source": [
    "x = tf_constant(3.0)\n",
    "with GradientTape() as tape:\n",
    "    tape.watch(x)\n",
    "    y = x * x\n",
    "    dy_dx = tape.gradient(y, x) \n",
    "    print(dy_dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HkBjrVuOkrET"
   },
   "source": [
    "A questo punto la domanda spontanea è: e quindi? Supponiamo di voler fare una regressione lineare. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w-Ky8LCHWba2"
   },
   "outputs": [],
   "source": [
    "set_random_seed(1102)\n",
    "\n",
    "x1 = tf_normal([1000]) # <-- feature 1\n",
    "x2 = tf_normal([1000]) # <-- feature 2\n",
    "x3 = tf_normal([1000]) # <-- feature 3\n",
    "\n",
    "# variabile target\n",
    "y = 3.0 * x1 - 5.0 * x2 - 1.0 * x3 # <-- coefficienti = (3.0, -5.0, -1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jDiiiE5Dk5yp"
   },
   "source": [
    "Supponiamo di non conoscere i ciefficienti a priori e di volerli ricavare dai dati. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-_TKhH-XY2T4",
    "outputId": "7403cfb9-6d27-4e16-8b6a-9c7d1b54d268"
   },
   "outputs": [],
   "source": [
    "c = Variable([0.0, 0.0, 0.0]) # <-- inizializzazione\n",
    "for j in range(100):\n",
    "    with GradientTape() as tape:\n",
    "        tape.watch(c)\n",
    "        y_pred = c[0] * x1 + c[1] * x2 + c[2] * x3 # <-- predizione\n",
    "        loss = tf_reduce_mean((y - y_pred)**2) # <-- quanto sto sbagliando?\n",
    "        grad =  tape.gradient(loss, c) # <-- differenziazione automatica\n",
    "        grad_normalized = grad / tf_sqrt(max(sum(grad**2), 0.00001)) \n",
    "        c = c - 10./(100.+j) * grad_normalized # <-- aggiorno i pesi\n",
    "        if (j+1) % 10 == 0:\n",
    "            print(\"iteration =\", j+1, \n",
    "                  \"\\t loss =\", loss.numpy(), \n",
    "                  #\"\\t grad =\", grad.numpy(), \n",
    "                  \"\\t norm grad =\", grad_normalized.numpy(), \n",
    "                  \"\\t coeff =\", c.numpy())\n",
    "print(\"Coefficients found\", c.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5jCvLaE4zUCW"
   },
   "source": [
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UgIoHO9Ryct8"
   },
   "source": [
    "### Caricamento dataset delle lettere\n",
    "\n",
    "Carichiamo il dataset delle lettere scritte a mano usando la funzione `extract_training_samples` e `extract_test_samples`. I dati così caricati sono già divisi in train set (usato per allenare i pesi della rete) e test set (dati non presenti durante il training e usati solo per testare le performance). \n",
    "\n",
    "Come primo passo, normalizziamo tutte le features nel range [0, 1] e facciamo in modo che le etichette abbiano una numerazione che inizi da 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pupyg-KIvWqR",
    "outputId": "a25b0f7e-df95-4a2f-9979-190ade6978d8"
   },
   "outputs": [],
   "source": [
    "letters_train_features, letters_train_labels \\\n",
    "= extract_training_samples('letters')\n",
    "letters_train_features = letters_train_features / 255.0\n",
    "letters_train_labels_one_hot = to_categorical(\n",
    "    letters_train_labels - 1, \n",
    "    len(unique(letters_train_labels))\n",
    ")\n",
    "\n",
    "print(\"Dimensioni della feature table =\", letters_train_features.shape)\n",
    "print(\"Dimensione del vettore target  =\", letters_train_labels_one_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TmtJOrs02xIn",
    "outputId": "9cb787b0-08f8-45a2-b1cd-b1244acedb58"
   },
   "outputs": [],
   "source": [
    "letters_test_features, letters_test_labels \\\n",
    "= extract_test_samples('letters')\n",
    "letters_test_features = letters_test_features / 255.0\n",
    "letters_test_labels_one_hot = to_categorical(\n",
    "    letters_test_labels - 1, \n",
    "    len(unique(letters_test_labels))\n",
    ")\n",
    "\n",
    "print(\"Dimensioni della feature table =\", letters_test_features.shape)\n",
    "print(\"Dimensione del vettore target  =\", letters_test_labels_one_hot.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_pFSdOw0ztqS"
   },
   "source": [
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Cbt4O0D1syr"
   },
   "source": [
    "### Visualizzazione dei dati\n",
    "\n",
    "Possiamo disegna qualche istanza del training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "id": "7aucg8UnyOjO",
    "outputId": "ced0f836-3b00-47db-a584-4126e17b9b93"
   },
   "outputs": [],
   "source": [
    "def plot_samples(data) -> None:\n",
    "    f, axarr = subplots(3,3)\n",
    "    rnd_ints = randint(low=0, high=data.shape[0], size=prod(axarr.shape))\n",
    "    for j, ax in enumerate([item for sublist in axarr for item in sublist]):\n",
    "        ax.imshow(data[rnd_ints[j]])\n",
    "    f.show()\n",
    "\n",
    "plot_samples(letters_train_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rMrIwSDo6KN-"
   },
   "source": [
    "### Distribuzione della variabile target\n",
    "\n",
    "Controlliamo che la variabile target sia equidistribuita nelle varie classi. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "id": "Dp9q3Z014goz",
    "outputId": "27a3b619-7407-4d68-96ac-8e3e65067b60"
   },
   "outputs": [],
   "source": [
    "hist(letters_train_labels, rwidth=0.5, bins=len(unique(letters_train_labels)))\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ExbXTDLzz1mL"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "abtrDnVI3hgN"
   },
   "source": [
    "### Prima rete neurale aritificiale\n",
    "\n",
    "In modo molto semplicistico, possiamo affermare che i tre ingredienti per una rete neurale artificiale sono:\n",
    "- architettura della rete; \n",
    "- la loss da minimizzare;\n",
    "- l'ottimizzatore che aggiorna i pesi della rete affinché la loss venga minimizzata. \n",
    "\n",
    "Partiamo dunque con l'architettura della rete concatenando in sequenza diversi layer già implementati in Tensorflow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8eaK6aVuPrI_"
   },
   "outputs": [],
   "source": [
    "set_random_seed(1102)\n",
    "\n",
    "def get_model_dummy(input_shape, output_shape, units=64) -> Model:\n",
    "    model = Sequential([\n",
    "        Flatten(input_shape=input_shape),\n",
    "        Dense(units, activation='relu'),\n",
    "        Dense(output_shape, activation=\"softmax\")\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "model_dummy = get_model_dummy(\n",
    "    letters_train_features.shape[1:], \n",
    "    len(unique(letters_train_labels)), \n",
    "    units=64\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4DsU6QdSbYzG"
   },
   "source": [
    "Possiamo anche disegnare la nostra rete usando il comando `plot_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 422
    },
    "id": "AQPZvmIhPswy",
    "outputId": "145e12be-11a3-4c6d-ac72-a2c0bf22d404"
   },
   "outputs": [],
   "source": [
    "plot_model(model_dummy, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b6IOlubHoAD0",
    "outputId": "0e7d9b7d-4f8d-427d-965d-af490be1985a"
   },
   "outputs": [],
   "source": [
    "for layer in model_dummy.layers:\n",
    "    print(\"\\n\", layer.name)\n",
    "    for w in layer.weights:\n",
    "        print(w.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QkTRs0uebjQn"
   },
   "source": [
    "Compiliamo la nostra prima rete specificando l'[ottimizzatore](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers), la [loss](https://www.tensorflow.org/api_docs/python/tf/keras/losses) e la [metrica di monitoraggio](https://www.tensorflow.org/api_docs/python/tf/keras/metrics). Quest'ultima non è strettamente necessaria ai fini del training ma può essere utile monitorarla. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KNiqqj2Lw3xG",
    "outputId": "9e21eac0-81e8-43c0-8aee-98795992466b"
   },
   "outputs": [],
   "source": [
    "model_dummy.compile(\n",
    "    optimizer='adam',\n",
    "    loss=CategoricalCrossentropy(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model_dummy.fit(\n",
    "    letters_train_features, letters_train_labels_one_hot, \n",
    "    batch_size=256, epochs=100, validation_split=0.2, verbose=2, \n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WruPJJcxIabe"
   },
   "source": [
    "### Proviamo con la convoluzione\n",
    "\n",
    "I [layer convoluzionali](https://www.wikiwand.com/it/Rete_neurale_convoluzionale) sono progettati appositamente per i task di computer vision. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "MNh57wDM-Aoe",
    "outputId": "34c13da5-e675-4ec4-e034-0db534cc15d9"
   },
   "outputs": [],
   "source": [
    "set_random_seed(1102)\n",
    "\n",
    "def get_model_conv(input_shape, output_shape) -> Model:\n",
    "    layer_input = Input(shape=input_shape)\n",
    "    reshaped = Reshape((28, 28, 1))(layer_input)\n",
    "\n",
    "    conv1 = Conv2D(32, (3,3))(reshaped)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = LeakyReLU()(conv1)\n",
    "    conv1 = MaxPool2D()(conv1)\n",
    "    conv1 = Flatten()(conv1)\n",
    "    conv1 = Dense(32, activation='sigmoid')(conv1)\n",
    "\n",
    "    drop2 = Dropout(0.05)(reshaped)\n",
    "    rot2 = RandomRotation(factor=(-0.05, +0.05))(drop2)\n",
    "    tran2 = RandomTranslation(\n",
    "        height_factor=(-0.05, +0.05), \n",
    "        width_factor=(-0.05, +0.05)\n",
    "    )(rot2)\n",
    "    conv2 = Conv2D(32, (5,5))(tran2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = LeakyReLU()(conv2)\n",
    "    conv2 = MaxPool2D()(conv2)\n",
    "    conv2 = Flatten()(conv2)\n",
    "    conv2 = Dense(32, activation='sigmoid')(conv2)\n",
    "\n",
    "    fc1 = Flatten()(reshaped)\n",
    "    fc1 = Dense(64, activation='sigmoid')(fc1)\n",
    "    fc1 = Dense(32, activation='sigmoid')(fc1)\n",
    "\n",
    "    layer_latent = Concatenate(name=\"model_conv_latent\")((conv1, conv2, fc1))\n",
    "    x = Dense(64, activation='linear')(layer_latent)\n",
    "    x = LeakyReLU()(x)\n",
    "    layer_output = Dense(output_shape, activation=\"softmax\")(x)\n",
    "    model = Model(layer_input, layer_output)\n",
    "    return model, layer_input, layer_latent\n",
    "\n",
    "model_conv, model_conv_input, model_conv_latent = get_model_conv(\n",
    "    letters_train_features.shape[1:], \n",
    "    len(unique(letters_train_labels))\n",
    ")\n",
    "\n",
    "plot_model(model_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iUyOhDNo_GSt",
    "outputId": "9d62642a-0ffc-4e59-ce65-f6e994eac634"
   },
   "outputs": [],
   "source": [
    "model_conv.compile(\n",
    "    optimizer='adam',\n",
    "    loss=CategoricalCrossentropy(),\n",
    ")\n",
    "\n",
    "model_conv.save(\"model_conv_random.h5\")\n",
    "\n",
    "model_conv.fit(\n",
    "    letters_train_features, letters_train_labels_one_hot, \n",
    "    batch_size=256, epochs=100, validation_split=0.2, verbose=2, \n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=3)]\n",
    ")\n",
    "\n",
    "model_conv.save(\"model_conv_trained.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vhXMGW11IgKl"
   },
   "source": [
    "### Performance sul test set\n",
    "\n",
    "Fin'ora abbiamo usato il training set e la validation set. Vediamo come le performance delle due reti sopra allenate sul test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qROGZ4tXANg4"
   },
   "outputs": [],
   "source": [
    "preds_dummy = model_dummy.predict(letters_test_features)\n",
    "print(\"Dummy model accuracy =\", sum(argmax(preds_dummy) == argmax(letter_test_labels_one_hot)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aMFMqmZXH59A"
   },
   "outputs": [],
   "source": [
    "preds_conv = model_conv.predict(letters_test_features)\n",
    "print(\"Conv model accuracy =\", sum(argmax(preds_conv) == argmax(letter_test_labels_one_hot)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4-4BFt8vhOrG"
   },
   "outputs": [],
   "source": [
    "del model_dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gBRju2PY2Ft6"
   },
   "source": [
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gciyy4P3Spwv"
   },
   "source": [
    "### Problema: training set molto piccolo\n",
    "\n",
    "Cambiamo il dataset. Questa volta prendiamo le immagini che riportano le cifre. Per complicarci le cose, selezioniamo casualmente solo 60 istanze dal training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f4cqCUqAIvSc",
    "outputId": "40a80e41-9974-44fc-ae11-a9c3100c27d0"
   },
   "outputs": [],
   "source": [
    "set_random_seed(1102)\n",
    "\n",
    "digits_train_features, digits_train_labels \\\n",
    "= extract_training_samples('digits')\n",
    "digits_train_features = digits_train_features / 255.0\n",
    "idx = choice(arange(0, digits_train_features.shape[0]), size=60, replace=False)\n",
    "digits_train_features = digits_train_features[idx, :, :]\n",
    "digits_train_labels = digits_train_labels[idx]\n",
    "\n",
    "print(\"Dimensioni della feature table =\", digits_train_features.shape)\n",
    "print(\"Dimensione del vettore target  =\", digits_train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y_-JQR-EIzCv",
    "outputId": "69c57333-9a81-4af2-bdf7-b1992d350578"
   },
   "outputs": [],
   "source": [
    "digits_test_features, digits_test_labels \\\n",
    "= extract_test_samples('digits')\n",
    "digits_test_features = digits_test_features / 255.0\n",
    "\n",
    "print(\"Dimensioni della feature table =\", digits_test_features.shape)\n",
    "print(\"Dimensione del vettore target  =\", digits_test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ChfWVSgTepI9"
   },
   "source": [
    "Come prima, ispezioniamo il dataset disegnando qualche istanza a video. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "id": "HuGMCnkbJEdc",
    "outputId": "017f97a1-d05b-4fc2-b49c-b9fa78010812"
   },
   "outputs": [],
   "source": [
    "plot_samples(digits_train_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tmkHcaTieyp1"
   },
   "source": [
    "E studiamo un attimo anche la distribuzione delle varie classi. Ci sono delle classi che hanno solo 3 istanze! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "bQrR3hX2K9ri",
    "outputId": "e0133703-0dd5-4ce8-9039-3c37e9c373b4"
   },
   "outputs": [],
   "source": [
    "hist(digits_train_labels, rwidth=0.5, bins=len(unique(digits_train_labels)))\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wZqZRGoMfGwt"
   },
   "source": [
    "Proviamo subito con una rete molto semplice per vedere fino a dove riusciamo ad arrivare. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OpUNzgtFLHwq"
   },
   "outputs": [],
   "source": [
    "set_random_seed(1102)\n",
    "\n",
    "model_dummy_4_digits = get_model_dummy(\n",
    "    digits_train_features.shape[1:], \n",
    "    len(unique(digits_train_labels)), \n",
    "    16\n",
    ")\n",
    "\n",
    "model_dummy_4_digits.compile(\n",
    "    optimizer='adam',\n",
    "    loss=SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CzbUuNVJghPE",
    "outputId": "f3891966-861d-4d7a-fe86-d5b7f39f8654"
   },
   "outputs": [],
   "source": [
    "model_dummy_4_digits.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uq3mL2fifQo_"
   },
   "source": [
    "Questa rete ha 12730 pesi allenabili. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zfImJ6HNSNy-",
    "outputId": "6b734d34-ece0-4621-cba8-01e87269f7e4"
   },
   "outputs": [],
   "source": [
    "model_dummy_4_digits.fit(\n",
    "    digits_train_features, digits_train_labels, \n",
    "    batch_size=256, epochs=100, validation_split=0.2, verbose=0, \n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O4xbQPiTQg1o",
    "outputId": "87d789ed-b746-49e6-fd13-9480e2524135"
   },
   "outputs": [],
   "source": [
    "model_dummy_4_digits.evaluate(digits_test_features, digits_test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6FN_lamUfXfQ"
   },
   "source": [
    "Non così male, considerando che abbiamo solo 60 istanze nel training set! Che cosa possiamo fare per migliorare? 3 Idee: \n",
    "\n",
    "- ottimizzare l'architettura della rete (esercizio a casa); \n",
    "- sfruttare il transfer learning; \n",
    "- generare dati sintetici. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ystgKA43vOf"
   },
   "source": [
    "--- \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9cF8PaJJSVTY"
   },
   "source": [
    "### Transfer Learning\n",
    "\n",
    "Una delle magie delle reti neurali è che possiamo prendere una rete allenata su un dominio diverso dal nostro e usarlo per migliorare il nostro task. In questo esempio specifico, prendiamo la **rete allenata sulle lettere dell'alfabeto**, togliamo gli ultimi layer, fissiamo i pesi e poi aggiungiamo un paio di layer fully-connected per imparare a **classificare le cifre**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zjc66abGiNfW",
    "outputId": "b5827916-0bc3-47cc-f071-69740bd5984d"
   },
   "outputs": [],
   "source": [
    "model_conv.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9QCLq7N8L05K"
   },
   "outputs": [],
   "source": [
    "set_random_seed(1102)\n",
    "\n",
    "layer_output_digits = Dense(len(unique(digits_train_labels)), activation=\"softmax\")(\n",
    "    Dense(64, activation=\"relu\")(model_conv_latent)\n",
    ")\n",
    "model_transfer = Model(model_conv_input, layer_output_digits)\n",
    "model_conv.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wc3U7vZCPHv2",
    "outputId": "44d2c520-1499-4c87-87a1-481cf10239c6"
   },
   "outputs": [],
   "source": [
    "model_transfer.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hc5kMA3pg5Sf"
   },
   "source": [
    "Da notare che i pesi allenabili sono solo 6858, che sono di meno rispetto a quelli della rete dummy che abbiamo usato sopra. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EwZlhchwPTMM",
    "outputId": "8d128ac9-9d53-40e1-a20c-ff2f58b58294"
   },
   "outputs": [],
   "source": [
    "set_random_seed(1102)\n",
    "\n",
    "model_transfer.compile(\n",
    "    optimizer='adam',\n",
    "    loss=SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_transfer.fit(\n",
    "    digits_train_features, digits_train_labels, \n",
    "    batch_size=256, epochs=100, validation_split=0.2, verbose=0, \n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "di0oenSv5Upu",
    "outputId": "e9fd0170-4498-4212-f6db-6e7dfbfd146c"
   },
   "outputs": [],
   "source": [
    "model_dummy_4_digits.evaluate(digits_test_features, digits_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "byDLf9rLQCLv",
    "outputId": "40a84098-8f57-429f-8884-47a6b477291b"
   },
   "outputs": [],
   "source": [
    "model_transfer.evaluate(digits_test_features, digits_test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "__EbiEfrhJgh"
   },
   "source": [
    "Siamo riusciti a migliorare! :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yRnIbTaEhtjA"
   },
   "outputs": [],
   "source": [
    "del model_dummy_4_digits\n",
    "del model_transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H4SSs4ng4p7B"
   },
   "source": [
    "--- \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2aeBHpKOhLnI"
   },
   "source": [
    "### Generazione dati sintetici\n",
    "\n",
    "Un'altra delle possibili applicazioni delle reti neurali è la generazione dei dati sintetici. In questo esempio, sfruttiamo un [autoencoder](https://www.wikiwand.com/en/Autoencoder). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W-HQYGp7jscW",
    "outputId": "c1a04c0a-fb2c-4204-a08f-4316fc8cc55b"
   },
   "outputs": [],
   "source": [
    "set_random_seed(1102)\n",
    "model_conv.trainable = False\n",
    "\n",
    "def get_model_ae(model_conv_input, model_conv_latent) -> Model:\n",
    "\n",
    "    bottleneck = Dense(32, activation='linear')(model_conv_latent)\n",
    "    model_encoder = Model(model_conv_input, bottleneck)\n",
    "\n",
    "    layer_input_dec = Input(shape=32)\n",
    "    x = Dense(64, activation='relu')(layer_input_dec)\n",
    "    layer_output_ae = Dense(784, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model_decoder = Model(layer_input_dec, layer_output_ae)\n",
    "\n",
    "    model_ae = Sequential([\n",
    "        model_encoder,\n",
    "        model_decoder,\n",
    "    ])\n",
    "\n",
    "    return model_ae, model_encoder, model_decoder\n",
    "\n",
    "model_ae, model_encoder, model_decoder = get_model_ae(\n",
    "    model_conv_input, model_conv_latent\n",
    ")\n",
    "\n",
    "model_ae.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B2DttAV3ibD3"
   },
   "source": [
    "Facciamo un training alternato lettere/numeri. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XlaSFuqEiZXB",
    "outputId": "7b72e776-7061-4cc8-d447-763331811ed0"
   },
   "outputs": [],
   "source": [
    "model_ae.compile(\n",
    "    optimizer=Adam(learning_rate=0.005, amsgrad=True),\n",
    "    loss=MeanSquaredError(),\n",
    "    metrics=['mse']\n",
    ")\n",
    "\n",
    "for epoch in range(20):\n",
    "    model_ae.fit(\n",
    "        letters_train_features, \n",
    "        letters_train_features.reshape(letters_train_features.shape[0], 784), \n",
    "        batch_size=1024, epochs=1, verbose=0\n",
    "    )\n",
    "    model_ae.fit(\n",
    "        digits_train_features, \n",
    "        digits_train_features.reshape(digits_train_features.shape[0], 784), \n",
    "        batch_size=32, epochs=1, validation_split=0.2, verbose=2\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S_TPiAeOil05"
   },
   "source": [
    "Proviamo ora a generare qualche istanza aggiungendo del rumore alla rappresentazione latente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3qUVNlymlGgU"
   },
   "outputs": [],
   "source": [
    "def show_synthetic_data(data) -> None:\n",
    "    synthetic_data = model_decoder.predict(\n",
    "        model_encoder.predict(\n",
    "            data\n",
    "        ) + normal(size=32, loc=0.0, scale=0.01)\n",
    "    ).reshape((data.shape[0], 28, 28))\n",
    "    synthetic_data_processed = minimum(exp(synthetic_data)-1, 1)\n",
    "\n",
    "    f, axarr = subplots(2, data.shape[0])\n",
    "    for j in range(data.shape[0]):\n",
    "        axarr[0][j].imshow(data[j])\n",
    "        axarr[1][j].imshow(synthetic_data_processed[j])\n",
    "    f.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-lMgDWBau7H7"
   },
   "outputs": [],
   "source": [
    "rnd_ints = randint(low=0, high=letters_train_features.shape[0], size=5)\n",
    "show_synthetic_data(letters_train_features[rnd_ints])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XCT8QkHGr2GQ"
   },
   "outputs": [],
   "source": [
    "rnd_ints = randint(low=0, high=digits_train_features.shape[0], size=5)\n",
    "show_synthetic_data(digits_train_features[rnd_ints])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Raocp5L4jWlh"
   },
   "source": [
    "Come possiamo sfruttare i dati sintetici per migliorare le performance di training? (Esercizio a casa) \n",
    "\n",
    "I dati sintetici generati non ti sembrano così realistici? Hai ragione, in realtà la questione è più complicata di così. Per approfondimenti, vedi [Variational Autoencoder](https://www.wikiwand.com/en/Variational_autoencoder). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wWLLs-2sAtDL"
   },
   "source": [
    "### Generative Adversarial Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c5usiBjtrwbt"
   },
   "outputs": [],
   "source": [
    "def get_model_generator():\n",
    "\n",
    "    layer_input = Input(shape=(100,))\n",
    "    x = Dense(7*7*256, use_bias=False)(layer_input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU()(x)\n",
    "\n",
    "    x = Reshape((7, 7, 256))(x)\n",
    "\n",
    "    x = Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False)(x)\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU()(x)\n",
    "\n",
    "    x = Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU()(x)\n",
    "\n",
    "    x = Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh')(x)\n",
    "    \n",
    "    layer_output = Reshape((28, 28))(x)\n",
    "\n",
    "    model = Model(layer_input, x)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "veg_PP16I50o"
   },
   "outputs": [],
   "source": [
    "def get_model_discriminator():\n",
    "\n",
    "    layer_input = Input((28, 28))\n",
    "\n",
    "    x = Reshape((28, 28, 1))(layer_input)\n",
    "\n",
    "    x = Conv2D(64, (5, 5), strides=(2, 2), padding='same')(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv2D(128, (5, 5), strides=(2, 2), padding='same')(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    layer_output = Dense(1)(x)\n",
    "\n",
    "    model = Model(layer_input, layer_output)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5u3AgYsDF438"
   },
   "outputs": [],
   "source": [
    "model_generator = get_model_generator()\n",
    "model_discriminator = get_model_discriminator()\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = BinaryCrossentropy(from_logits=True)(ones_like(real_output), real_output)\n",
    "    fake_loss = BinaryCrossentropy(from_logits=True)(zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return BinaryCrossentropy(from_logits=True)(ones_like(fake_output), fake_output)\n",
    "\n",
    "optimizer_generator = Adam(1e-4)\n",
    "optimizer_discriminator = Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k-6oXj-rF8OG"
   },
   "outputs": [],
   "source": [
    "@tf_function\n",
    "def train_step(images, batch_size):\n",
    "\n",
    "    noise = tf_normal([batch_size, 100])\n",
    "\n",
    "    with GradientTape() as tape_generator, GradientTape() as tape_discriminator:\n",
    "\n",
    "        generated_images = model_generator(noise, training=True)\n",
    "\n",
    "        real_output = model_discriminator(images, training=True)\n",
    "        fake_output = model_discriminator(generated_images, training=True)\n",
    "\n",
    "        loss_generator = generator_loss(fake_output)\n",
    "        loss_discriminator = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    grad_generator = tape_generator.gradient(loss_generator, model_generator.trainable_variables)\n",
    "    grad_discriminator = tape_discriminator.gradient(loss_discriminator, model_discriminator.trainable_variables)\n",
    "\n",
    "    optimizer_generator.apply_gradients(zip(grad_generator, model_generator.trainable_variables))\n",
    "    optimizer_discriminator.apply_gradients(zip(grad_discriminator, model_discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mPMGG_hwDJx8"
   },
   "outputs": [],
   "source": [
    "for epoch in range(500):\n",
    "    if (epoch+1)%5 == 0:\n",
    "        print(\"epoch =\", epoch+1)\n",
    "    for image_batch in Dataset.from_tensor_slices(letters_train_features).batch(1024):\n",
    "        train_step(image_batch, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YDNSIM9BNsTr"
   },
   "outputs": [],
   "source": [
    "synthetic = model_generator.predict(tf_normal([5, 100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SAXPV7rkOool"
   },
   "outputs": [],
   "source": [
    "f, axarr = subplots(1, synthetic.shape[0])\n",
    "f.set_dpi(300)\n",
    "for j in range(synthetic.shape[0]):\n",
    "    axarr[j].imshow(synthetic[j].reshape((28, 28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m8pcYZygPCPF"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ISP_Tutorial_NN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
